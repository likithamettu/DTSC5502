{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOCcwJTYcE2Foha7hNz22PK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC5502/blob/main/Module_01-Introduction/Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "cr2Fhm59lAZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started\n",
        "\n",
        "* Colab - get notebook from gitmystuff DTSC5502 repository\n",
        "* Save a Copy in Drive\n",
        "* Remove Copy of\n",
        "* Edit your name\n",
        "* Clean up Colab Notebooks folder\n",
        "* Submit shared link"
      ],
      "metadata": {
        "id": "tv86CANY3_Xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Learn Anything: consume content, mentorship, do it, teach\n",
        "* The function: $f(x)$\n",
        "* Ethics and Human Bias"
      ],
      "metadata": {
        "id": "V5Am0Y80ecsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Science\n",
        "\n",
        "* https://miro.medium.com/v2/resize:fit:1400/1*PzzcJA-cwXQ8hwlpM4DwbA@2x.jpeg drawn by Chanin Nantasenamat in collaboration with Ken Jee\n",
        "* https://towardsdatascience.com/the-data-science-process-a19eb7ebc41b\n",
        "* https://www.simplilearn.com/tutorials/data-science-tutorial/how-to-become-a-data-scientist#skills_to_become_a_data_scientist\n",
        "* https://towardsdatascience.com/my-honest-advice-for-someone-who-wants-to-become-a-data-scientist-1ecc018fb0b2\n",
        "* https://www.kdnuggets.com/10-python-libraries-every-data-scientist-should-know\n",
        "* https://www.businessinsider.com/gen-z-data-scientist-debunks-ai-job-myths-2024-8\n",
        "* https://www.kdnuggets.com/10-statistics-questions-to-ace-your-data-science-interview\n",
        "* https://towardsdatascience.com/how-i-landed-3-data-science-job-offers-in-one-month-8d4413c53c07\n",
        "* https://towardsdatascience.com/why-it-feels-impossible-to-get-a-data-science-job-398d57de464c\n",
        "* https://towardsdatascience.com/how-to-ace-data-science-interviews-50c9fae55dec\n",
        "\n"
      ],
      "metadata": {
        "id": "ibGc8MYhWUWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Readings\n",
        "\n",
        "* Outlines.xlsx"
      ],
      "metadata": {
        "id": "nHhCSkUFILVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Brief History\n",
        "\n",
        "* https://www.youtube.com/watch?v=x-A3vJ5ZjUI"
      ],
      "metadata": {
        "id": "7aX_x5LkW988"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Astronomy, Agriculture, and Navigation 600 BCE\n",
        "\n",
        "* Pythagorean Theorem: Finding the side of a right triangle ($a^2 + b^2 = c^2$)\n",
        "* Pythagorean Triples\n",
        "* Sum of Squares: $\\frac{1}{N}\\sum(x - \\hat{x})^2$\n",
        "* Variance (from Wikipedia): $Var(X) = E[(X-E[X])^2] = E[X^2] - (E[X])^2$\n",
        "* Geometry: Models the physical world, projecting a sphere onto a plane\n",
        "* Euclid Elements (point, line, plane, distance, angle, surface, and curve)\n",
        "* Astronomy\n",
        "\n",
        "Sources:\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Pythagorean_theorem\n",
        "* https://demonstrations.wolfram.com/SquareOfTheSumOfTwoNumbers/\n",
        "* https://www.thoughtco.com/sum-of-squares-formula-shortcut-3126266\n",
        "* https://en.wikipedia.org/wiki/History_of_astronomy\n",
        "* https://en.wikipedia.org/wiki/History_of_mathematics\n",
        "* https://en.wikipedia.org/wiki/Geometry"
      ],
      "metadata": {
        "id": "zoM_GIN4timE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Presentism\n",
        "\n",
        "And other biases\n",
        "* Selection bias: A common type of bias in studies, selection bias can be controlled for by using masking, random design, and proper case control groups.\n",
        "* Sampling bias: This bias occurs when the data used to train a model doesn't reflect the distribution of the samples it will receive in production.\n",
        "* Confirmation bias: A common cognitive bias that affects researchers and data analysts, confirmation bias occurs when people use new information to confirm their existing beliefs.\n",
        "* Observer bias: A type of detection bias, observer bias is when there is a systematic divergence from accurate facts during observation and data recording.\n",
        "* Survivorship bias: A type of selection bias that occurs when data set evaluation is distorted by focusing on successful cases while ignoring failures.\n",
        "* Availability bias: A mental shortcut that relies on immediate examples that come to a given person's mind when evaluating a specific topic, concept, method, or decision.\n",
        "* Recall bias: This occurs when the participants in a research study may not remember previous events or experiences accurately or they may subconsciously alter their memories. This can lead to skewed data and ultimately impact the credibility of the research results."
      ],
      "metadata": {
        "id": "lLMyXcSuurr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Binomial\n",
        "\n",
        "Used to determine the likelihood of successful and unsuccessful outcomes in a given number of trials.\n",
        "\n",
        "* Euclid\n",
        "* Pingala: Chandahsastra\n",
        "* Bhaskara: Lilavati\n",
        "* Al-Karaji: The Book of Algebra\n",
        "* $(a+b)^2 = a^2 + b^2 + 2ab$\n",
        "* $(x+y)^2 = x^4 + 4x^3y + 6x^2y^2 + 4xy^3 + y^4$\n",
        "* $P(x: n,p) = \\binom {n}{x} p^x (1 - p)^{(n-x)}$\n",
        "\n",
        "Practical Uses:\n",
        "\n",
        "* Number of ways to choose a certain number of objects from a set\n",
        "* Metrical patterns (if a meter has 4 syllables, the binomial expansion $= (Short + Long)^4$\n",
        "* Astronomy and Calendars which rely on precision\n",
        "* Area, volume, and other geometric calculations\n",
        "* Dividing property such as inheritance\n",
        "* Gambling and games of chance\n",
        "* With a large $n$, the binomial begins to look normal\n",
        "\n",
        "Sources:\n",
        "\n",
        "* https://nonagon.org/ExLibris/euclids-greatest-hits\n",
        "* https://en.wikipedia.org/wiki/Binomial_theorem"
      ],
      "metadata": {
        "id": "BYexsjwr8PnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gambling 1500s - 1600s\n",
        "\n",
        "* Probability (Event) = Favorable Outcomes / Total Possible Outcomes\n",
        "* Casting Lots\n",
        "* Cardano: The ratio of the number of favorable outcomes to the number of all possible outcomes determines the probability of an event\n",
        "* Modern notation P(E) = f / n where f represents favorable outcomes and n represents number of possible outcomes\n",
        "* Note: Cardano and his contemporaries didn't fully formalize probability theory as we know it today\n",
        "* Galileo\n",
        "* Pascal\n",
        "* Fermat\n",
        "* Note: Pascal and Fermat provide the modern concepts of probability\n",
        "\n",
        "Readings:\n",
        "\n",
        "* https://www.gameludere.com/2020/03/30/cardano-gambling-dawn-of-probability-theory/\n",
        "* https://mathigon.org/timeline"
      ],
      "metadata": {
        "id": "nN6toMTWtgRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medicine and Finance 1600s - 1700s\n",
        "\n",
        "* Bernoulli and Arbuthnot\n",
        "* Population vs Sample\n",
        "* The Expected Value vs Mean\n",
        "* E(X) = 1(1/6) + 2(1/6) + 3(1/6) + 4(1/6) + 5(1/6) + 6(1/6) = 3.5\n",
        "* $\\bar{X}$ = (5 + 2 + 6 + 2 + 2 + 1 + 2 + 3 + 6 + 1)/10 = 3.0\n",
        "* $\\bar{x}_n = (x_1 + x_2 + x_3 + ... + x_n) / n$\n",
        "* Law of large numbers\n",
        "* Sample average converges to the expected value: $\\bar{x}_n \\rightarrow \\mu$ as $n \\rightarrow \\infty$\n",
        "* Hypothesis testing: $\\mu_1 = \\mu_2$\n",
        "* An Argument for Divine Providence - Arbuthnot (1710) determined that the probability of observing more male births in 82 consecutive years under the null hypothesis was exceedingly small ~ 1 in $2^82$ providing evidence to reject null hypothesis of 50 50\n",
        "* Sex ratio binomial?\n",
        "* Laplace (1778) working similarly except compared London to Paris and concluded that there was something that facilitated the birth of males more so in London (climate or mothers)\n",
        "\n",
        "Readings:\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Law_of_large_numbers\n",
        "* https://math.stackexchange.com/questions/904343/what-is-the-difference-between-average-and-expected-value\n",
        "* https://en.wikipedia.org/wiki/Law_of_large_numbers\n",
        "* https://en.wikipedia.org/wiki/John_Arbuthnot\n",
        "* https://towardsdatascience.com/comparing-sex-ratios-revisiting-a-famous-statistical-problem-from-the-1700s-720cd57872c6"
      ],
      "metadata": {
        "id": "UuE8Hjddtti2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Homme Moyen 1800s\n",
        "\n",
        "* Adolph Quetelet - Belgian Astronomer and statistician\n",
        "* Collected data, height, weight, chest and saw a normal distribution\n",
        "* Applied these methods to moral and intellectual qualities, crime rates, marriage rates, suicide\n",
        "* Created the Quetelet Index or BMI\n",
        "* Average Man has been criticized for oversimplification\n",
        "\n",
        "Sources:\n",
        "\n",
        "* https://www.researchgate.net/figure/Descriptive-statistics-for-age-height-mass-Quetelets-Index-BMI-skinfolds-and-body_tbl1_7936811"
      ],
      "metadata": {
        "id": "M1CSedPdtwe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression 1800s - 1900s\n",
        "\n",
        "* Galton, Pearson, Fischer\n",
        "* Prasanta Chandra Mahalanobis\n",
        "* $y = \\beta_0 + \\beta_1X_1 + \\beta_2X2 + ... + \\beta_nX_n$\n",
        "* S(imple)L(inear)R(egression) without intercept is Pearson's r\n",
        "* $y = \\beta X + \\epsilon$ or $y_i = \\theta^TX_i + \\epsilon_i$\n",
        "* Logistic Regression: $\\sigma(\\beta X + \\epsilon)$\n",
        "* Perceptron: $\\sum{w_i x_i} + b$ or with activation function $f(\\sum{w_i x_i} + b)$\n",
        "* AND Gate\n",
        "\n",
        "Sources:\n",
        "\n",
        "* https://sjdr.se/articles/10.1080/15017410600608491 (Galton's view of social structure)\n",
        "* https://en.wikipedia.org/wiki/Coefficient_of_determination#As_squared_correlation_coefficient\n",
        "* https://c-tan.com/img/posts/screenshots/scrot_latex_math_cheatsheet_2018-01-13.png\n",
        "* https://aiml.com/wp-content/uploads/2023/09/perceptron-a-neuron-2.png\n",
        "* https://ecostat.kerala.gov.in/page/p-c-mahalanobis"
      ],
      "metadata": {
        "id": "4FeflhQ8CvN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Structural Equation Modeling 1900s - 2000s\n",
        "\n",
        "* Sewall Wright\n",
        "* Wright vs Fischer\n",
        "* https://www.kdnuggets.com/2017/03/structural-equation-modeling.html"
      ],
      "metadata": {
        "id": "RS7aHQa_uZxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "A6GwYxQOtV2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Story\n",
        "\n",
        "* Data vs Datum (singular of water - non count noun, mass noun)\n",
        "* Each snowflake is unique\n",
        "* Patterns in a snow storm\n",
        "* After the snow had come to rest (data in use, data in motion, data at rest)\n",
        "  * https://www.alamy.com/wind-blown-snow-patterns-late-winter-snow-storm-eastern-north-america-by-dominique-brauddembinsky-photo-assoc-image257568632.html\n",
        "  * https://www.alamy.com/patterns-in-drifted-snow-after-a-storm-image4253120.html\n",
        "* Pattern result of snow or environment?"
      ],
      "metadata": {
        "id": "QsDoD7_OzNYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# look at population data"
      ],
      "metadata": {
        "id": "wYHi3TEk35qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Population Variance: $\\sigma^2 = \\frac{1}{N}\\sum{(x - \\mu)^2} = E[x^2] - \\mu^2$\n",
        "* Sample Variance: $s^2 = \\frac{1}{n-1}\\sum{(x - \\bar{x})^2}$\n",
        "* unbiased vs biased\n",
        "* Sample Standard Deviation: $s = \\sqrt{\\frac{1}{n-1}\\sum{(x - \\bar{x})^2}}$\n",
        "* The Mean: $\\frac{\\sum_{i=1}^{n}(x_i)}{n}$"
      ],
      "metadata": {
        "id": "aQu9m5F737t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# look at sample data"
      ],
      "metadata": {
        "id": "sSlPrnjG8hoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advertising\n",
        "\n",
        "* Plotly Advertising"
      ],
      "metadata": {
        "id": "pEdQIpwVrJSi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0fcun3Nk8U4"
      },
      "outputs": [],
      "source": [
        "# # get data\n",
        "# import pandas as pd\n",
        "\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/gitmystuff/Datasets/main/Advertising.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# describe"
      ],
      "metadata": {
        "id": "JIP1eEzMlgLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot histograms"
      ],
      "metadata": {
        "id": "dkhtbHk7llHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pairplot example with seaborn (sns)\n"
      ],
      "metadata": {
        "id": "DuaujFz3lnXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relationships\n",
        "\n",
        "**Univariate Data**: data that consists of observations on a single characteristic or attribute\n",
        "\n",
        "**Bivariate Data**: data on each of two variables, where each value of one of the variables is paired with a value of the other variable\n",
        "\n",
        "**Multivariate Data**: a data set that contains multiple variables or features for each observation or sample point\n",
        "\n",
        "**Covariance**: measures the relationship between two variables, it is similar to variance, but while variance quantifies the variability of a single variable, covariance quantifies how two variables vary together. The measure can be positive, negative, or zero:\n",
        "\n",
        "* Positive covariance = an overall tendency for variables to move together. Data points will trend upwards on a graph.\n",
        "* Negative covariance = a overall tendency that when one variable increases, so does the other. Data points will trend downward on a graph.\n",
        "\n",
        "A high covariance indicates a strong relationship between the variables, while a low value suggests a weak relationship. However, unlike the correlation coefficient — which ranges from 0 to 1 — covariance has no limitations on its values, which can make it challenging to interpret.\n",
        "\n",
        "**Correlation**: Measures relationships showing direction and strength. While Cov. has no limitations on its values, correlation is restricted to the range of -1 to +1.\n",
        "\n",
        "* Due to its numerical constraints, correlation is more suitable for determining the strength of the relationship between the two variables: a correlation coefficient of 0 indicates no relationship, a correlation coefficient of 1 or -1 indicates a perfect relationship.\n",
        "* Correlation is unitless, whereas covariance always carries units. This is because the correlation coefficient is standardized, which removes units of measurement from calculations. This makes it easier to interpret the correlation coefficient.\n",
        "* Correlation is unaffected by changes in the center of a distribution (e.g., mean) or scale of the variables. This is because the correlation coefficient is calculated using deviations from the mean of the variables.\n",
        "\n",
        "https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/covariance/#advantages"
      ],
      "metadata": {
        "id": "3NAdNUGpX1AB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Covariance\n",
        "\n",
        "* Variance: $\\frac{1}{n-1}\\sum{(x - \\bar{x})^2}$\n",
        "* Covariance: $\\frac{1}{n-1}\\sum{(x - \\bar{x})(y - \\bar{y}})$"
      ],
      "metadata": {
        "id": "JfyDivvVD5qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# variance and covariance"
      ],
      "metadata": {
        "id": "SOqylOiyB_Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# covariance matrix - https://www.statology.org/how-to-read-covariance-matrix/"
      ],
      "metadata": {
        "id": "AtgxhtQPFz88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation\n",
        "\n",
        "* $r = \\frac{\\sum(x - \\bar{x})(y - \\bar{y})}{\\sigma_x\\sigma_y}$\n",
        "* Normalized version of covariance"
      ],
      "metadata": {
        "id": "KBWxM4fRArnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df cov"
      ],
      "metadata": {
        "id": "y0TrVEUcRvVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df corr"
      ],
      "metadata": {
        "id": "_G9osePbAj37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x corr with y"
      ],
      "metadata": {
        "id": "TH98P6fM_thl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corrwith plot"
      ],
      "metadata": {
        "id": "TEdUJm4NnZqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Covariance Data"
      ],
      "metadata": {
        "id": "8_c3wiTqzKKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate normal univariate data with mu and stdev\n"
      ],
      "metadata": {
        "id": "CNersxKeBBoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # generate normal bivariate data with mu and stdev\n",
        "# https://stackoverflow.com/questions/45952895/generating-correlated-numbers-in-numpy-pandas\n",
        "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.multivariate_normal.html\n",
        "\n"
      ],
      "metadata": {
        "id": "6KWK_FpyzGL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normal Distribution\n",
        "\n",
        "Note: The following equation is the PDF for a Normal distribution with a single X variable. The next equation extends the idea to X that have multiple values; it comes from the SciPy documentation and incorrectly uses k (number of clusters) rather than the correct d (input dimension).\n",
        "\n",
        "https://jamesmccaffrey.wordpress.com/2019/07/22/multivariate-normal-probability-density-function-in-python/\n",
        "\n",
        "$f(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi * \\sigma^2}}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$\n",
        "\n",
        "Python:\n",
        "<pre>\n",
        "1/(np.sqrt(2 * np.pi * sigma**2)) * np.exp( - (bins - mu)**2 / (2 * sigma**2) )\n",
        "</pre>"
      ],
      "metadata": {
        "id": "JzTm7863omMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standard normal distribution with numpy\n",
        "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n"
      ],
      "metadata": {
        "id": "cOgEid0Bv7jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multivariate Normal Distribution\n",
        "\n",
        "$p(x; \\mu, \\Sigma) = \\frac{1}{\\sqrt{(2\\pi)^\\frac{k}{2} |\\Sigma|^\\frac{1}{2}}} * e^({-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1} * (x - \\mu))}$"
      ],
      "metadata": {
        "id": "hTy_r4NlpUBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://stackoverflow.com/questions/28342968/how-to-plot-a-2d-gaussian-with-different-sigma\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from matplotlib import cm\n",
        "# from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# # Our 2-dimensional distribution will be over variables X and Y\n",
        "# N = 40\n",
        "# X = np.linspace(-2, 2, N)\n",
        "# Y = np.linspace(-2, 2, N)\n",
        "# X, Y = np.meshgrid(X, Y)\n",
        "\n",
        "# # Mean vector and covariance matrix\n",
        "# mu = np.array([0., 0.])\n",
        "# Sigma = np.array([[ 1. , -0.5], [-0.5,  1.]])\n",
        "\n",
        "# # Pack X and Y into a single 3-dimensional array\n",
        "# pos = np.empty(X.shape + (2,))\n",
        "# pos[:, :, 0] = X\n",
        "# pos[:, :, 1] = Y\n",
        "\n",
        "# def multivariate_gaussian(pos, mu, Sigma):\n",
        "#     \"\"\"Return the multivariate Gaussian distribution on array pos.\"\"\"\n",
        "\n",
        "#     n = mu.shape[0]\n",
        "#     Sigma_det = np.linalg.det(Sigma)\n",
        "#     Sigma_inv = np.linalg.inv(Sigma)\n",
        "#     N = np.sqrt((2*np.pi)**n * Sigma_det)\n",
        "#     # This einsum call calculates (x-mu)T.Sigma-1.(x-mu) in a vectorized\n",
        "#     # way across all the input variables.\n",
        "#     fac = np.einsum('...k,kl,...l->...', pos-mu, Sigma_inv, pos-mu)\n",
        "\n",
        "#     return np.exp(-fac / 2) / N\n",
        "\n",
        "# # The distribution on the variables X, Y packed into pos.\n",
        "# Z = multivariate_gaussian(pos, mu, Sigma)\n",
        "\n",
        "# # plot using subplots\n",
        "# fig = plt.figure(figsize=(10,10))\n",
        "# ax1 = fig.add_subplot(2,1,1,projection='3d')\n",
        "\n",
        "# ax1.plot_surface(X, Y, Z, rstride=3, cstride=3, linewidth=1, antialiased=True,\n",
        "#                 cmap=cm.viridis)\n",
        "# ax1.view_init(55,-70)\n",
        "# # ax1.set_xticks([])\n",
        "# # ax1.set_yticks([])\n",
        "# # ax1.set_zticks([])\n",
        "# ax1.set_xlabel(r'$x_1$')\n",
        "# ax1.set_ylabel(r'$x_2$')\n",
        "\n",
        "# ax2 = fig.add_subplot(2,1,2,projection='3d')\n",
        "# ax2.contourf(X, Y, Z, zdir='z', offset=0, cmap=cm.viridis)\n",
        "# ax2.view_init(90, 270)\n",
        "\n",
        "# ax2.grid(False)\n",
        "# # ax2.set_xticks([])\n",
        "# # ax2.set_yticks([])\n",
        "# ax2.set_zticks([])\n",
        "# ax2.set_xlabel(r'$x_1$')\n",
        "# ax2.set_ylabel(r'$x_2$')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "dttBQrqAsi9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://stackoverflow.com/questions/70426129/how-to-simulate-multi-collinearity-using-sklearn\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "# import statsmodels.api as sm\n",
        "\n",
        "# n_samples=200\n",
        "# n_uncorrelated=1\n",
        "# n_correlated=2\n",
        "# correlation=0.8\n",
        "# weights=[0.5, 0.5, 0.5]\n",
        "# bias=0\n",
        "# seed=42\n",
        "# noise=1\n",
        "\n",
        "# # def make_regression(n_samples, n_uncorrelated, n_correlated, correlation, weights, bias, noise=1, seed=42):\n",
        "\n",
        "# np.random.seed(seed)\n",
        "\n",
        "# X_uncorrelated = np.random.multivariate_normal(\n",
        "#     mean=np.zeros(n_uncorrelated),\n",
        "#     cov=np.eye(n_uncorrelated),\n",
        "#     size=n_samples\n",
        "# )\n",
        "\n",
        "# X_correlated = np.random.multivariate_normal(\n",
        "#     mean=np.zeros(n_correlated),\n",
        "#     cov=correlation * np.ones((n_correlated, n_correlated)) + (1 - correlation) * np.eye(n_correlated),\n",
        "#     size=n_samples\n",
        "# )\n",
        "# # print(np.zeros(n_correlated))\n",
        "# # print(np.ones((n_correlated, n_correlated)))\n",
        "# # print(np.eye(n_correlated))\n",
        "# print('Correlated Matrix')\n",
        "# print(correlation * np.ones((n_correlated, n_correlated)) + (1 - correlation) * np.eye(n_correlated))\n",
        "# # print(correlation * np.ones((n_correlated, n_correlated)))\n",
        "# # print((1-correlation) * np.eye(n_correlated))\n",
        "# print()\n",
        "\n",
        "# X = np.hstack([X_correlated, X_uncorrelated])\n",
        "# e = np.random.normal(loc=0, scale=noise, size=n_samples)\n",
        "# y = bias + np.dot(X, weights) + e\n",
        "\n",
        "# # return X, y\n",
        "\n",
        "# # X, y = make_regression(\n",
        "# #     n_samples=200,\n",
        "# #     n_uncorrelated=1,\n",
        "# #     n_correlated=2,\n",
        "# #     correlation=0.8,\n",
        "# #     weights=[0.5, 0.5, 0.5],\n",
        "# #     bias=0,\n",
        "# # )\n",
        "\n",
        "# model = LinearRegression()\n",
        "# model.fit(X, y)\n",
        "\n",
        "# print('Model From Code')\n",
        "# print(model.intercept_)\n",
        "# print(model.coef_)\n",
        "# print()\n",
        "\n",
        "# print('Model From Statsmodels with Correlation and Pairplot')\n",
        "# df = pd.DataFrame(X, columns=['x1', 'x2', 'x3'])\n",
        "# df['y'] = y\n",
        "\n",
        "# print('Covariance')\n",
        "# print(df.cov())\n",
        "# print('Correlation')\n",
        "# # print(df.head())\n",
        "# print(df.corr())\n",
        "# print()\n",
        "\n",
        "# print('OLS Summary')\n",
        "# X = df.drop('y', axis=1)\n",
        "# y = df['y']\n",
        "# X.insert(0, 'const', 1)\n",
        "# model = sm.OLS(y, X).fit()\n",
        "# print(model.summary())\n",
        "# print()\n",
        "\n",
        "# print('Pairplot')\n",
        "# g = sns.pairplot(df, x_vars=['x1','x2','x3'], y_vars='y',\n",
        "#              kind='reg',\n",
        "#              height=5,\n",
        "#              aspect=0.8,\n",
        "#              plot_kws={'ci': None, 'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.5}});\n",
        "\n",
        "# for ax in g.axes.ravel():\n",
        "#     ax.axhline(y=0, ls='--', c='cyan')\n",
        "#     ax.axvline(x=0, ls='--', c='cyan')\n",
        "# plt.show()\n",
        "\n",
        "# X.drop('const', axis=1).corrwith(y).plot.bar(\n",
        "#         title = \"Correlation with Target\", fontsize = 15,\n",
        "#         rot = 45, grid = True);"
      ],
      "metadata": {
        "id": "1R2LA0Qa31u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Regression\n",
        "\n",
        "* https://machinelearningmastery.com/robust-regression-for-machine-learning-in-python/"
      ],
      "metadata": {
        "id": "_P6DcFGKqSWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example with make_regression\n"
      ],
      "metadata": {
        "id": "5tIQz7UDoWbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scatterplot example with seaborn (sns)\n"
      ],
      "metadata": {
        "id": "TxUp5tnApIoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describe"
      ],
      "metadata": {
        "id": "CXNmcDQ0orQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# histograms"
      ],
      "metadata": {
        "id": "QVsTv5qTouoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corr with"
      ],
      "metadata": {
        "id": "KIFnrocIpjwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# statsmodel ols"
      ],
      "metadata": {
        "id": "y4eAu-80q7vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "747b9656"
      },
      "source": [
        "### Linear Algebra\n",
        "\n",
        "* $y_i = \\theta^TX_i + \\epsilon_i$\n",
        "* $h_\\theta(x) = \\theta_0 + \\theta_1x_1$\n",
        "* $\\theta = (X^T * X)^{-1} * X^T * y$\n",
        "* Dot product - https://en.wikipedia.org/wiki/Dot_product\n",
        "* Inverse - https://www.mathsisfun.com/algebra/matrix-inverse.html\n",
        "* To multiply an m×n matrix by an n×p matrix, the ns must be the same,\n",
        "and the result is an m×p matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "Readings:\n",
        "\n",
        "* https://timeseriesreasoning.com/contents/deep-dive-into-variance-covariance-matrices/\n",
        "* https://www.jeremyjordan.me/intro-to-neural-networks/\n",
        "* https://www.varsitytutors.com/hotmath/hotmath_help/topics/multiplying-vector-by-a-matrix\n",
        "* https://towardsdatascience.com/performing-linear-regression-using-the-normal-equation-6372ed3c57\n",
        "* https://mathinsight.org/matrix_vector_multiplication"
      ],
      "metadata": {
        "id": "DEB0SsTgTl6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # put it all in one cell\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import statsmodels.api as sm\n",
        "\n",
        "# advertising = pd.read_csv('https://raw.githubusercontent.com/gitmystuff/INFO4050/main/Datasets/Advertising.csv', usecols=['TV', 'radio', 'newspaper', 'sales'])\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     advertising.drop('sales', axis=1),\n",
        "#     advertising['sales'],\n",
        "#     test_size=0.25,\n",
        "#     random_state=42)\n",
        "\n",
        "# X_train.insert(0, 'const', 1)\n",
        "# X = X_train\n",
        "# y = y_train\n",
        "\n",
        "# model = sm.OLS(y, X).fit()\n",
        "# print('StatsModel')\n",
        "# print(model.params)\n",
        "# print()\n",
        "# print('Numpy Linear Algebra')\n",
        "# print('weights = ', np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y))\n",
        "# np.matmul(np.linalg.inv(np.matmul(X.values.T, X.values)), np.matmul(X.values.T, y))"
      ],
      "metadata": {
        "id": "zE5rbneAASfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical Data"
      ],
      "metadata": {
        "id": "hZyhPpZz6Cyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/32633977/how-to-create-categorical-variable-based-on-a-numerical-variable\n",
        "# https://stackoverflow.com/questions/58163835/make-regression-model-with-categorical-data-with-scikit-learn\n"
      ],
      "metadata": {
        "id": "W2_Q1gBcZ-gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# value counts"
      ],
      "metadata": {
        "id": "WU21auy7cYUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# putting it all together playground\n"
      ],
      "metadata": {
        "id": "lZ1FkJh5u7Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistics\n",
        "\n",
        "* Descriptive\n",
        "* Probability\n",
        "* Distributions\n",
        "* Hypothesis Testing\n",
        "* GLMs"
      ],
      "metadata": {
        "id": "GtqRjtTOVlhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Maths\n",
        "\n",
        "* Linear algebra\n",
        "* Calculus\n",
        "* Derivatives\n",
        "* Functions: https://github.com/gitmystuff/DSChunks/blob/main/Functions.ipynb\n",
        "* Minimum of a function\n",
        "* Cost of a function"
      ],
      "metadata": {
        "id": "wQ1inZ-xgO47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Database\n",
        "\n",
        "* Normalization\n",
        "* ACID\n",
        "* SQL\n",
        "* Unique Key\n",
        "* Foreign Key\n",
        "* Using with Python"
      ],
      "metadata": {
        "id": "jaMsMp1xy5fG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computer Science\n",
        "\n",
        "* Memory\n",
        "* Data Structures\n",
        "* Big O\n",
        "* Hash Tables\n",
        "* Search\n",
        "* SOLID"
      ],
      "metadata": {
        "id": "Rv-AINNLy7eH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working in the Cloud\n",
        "\n",
        "* https://aws.amazon.com/education/awseducate/"
      ],
      "metadata": {
        "id": "eXopJXHCaJCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ethics"
      ],
      "metadata": {
        "id": "7S161y_6WMCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Large Language Models"
      ],
      "metadata": {
        "id": "kkI0CjX2KrlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Brief History\n",
        "\n",
        "* https://colah.github.io/\n",
        "* http://neuralnetworksanddeeplearning.com/\n",
        "* https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\n",
        "* https://www.youtube.com/channel/UCYh1zKnwzrSjrO2Ae-akfTg/videos\n",
        "* ANNs\n",
        "* CNNs\n",
        "* RNNs\n",
        "* LSTMs\n",
        "* Attention\n",
        "* Reinforcement Learning\n"
      ],
      "metadata": {
        "id": "YnvYmgHATZab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention is All You Need\n",
        "\n",
        "* https://towardsdatascience.com/contextual-transformer-embeddings-using-self-attention-explained-with-diagrams-and-python-code-d7a9f0f4d94e\n",
        "* https://towardsdatascience.com/what-are-query-key-and-value-in-the-transformer-architecture-and-why-are-they-used-acbe73f731f2#:~:text=So%20the%20whole%20notion%20of,the%20context%20(the%20values)"
      ],
      "metadata": {
        "id": "OcPbMfnrg2Yb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Embeddings\n",
        "\n",
        "* From Scratch\n",
        "* Weaviate\n",
        "* Pinecone\n",
        "* Chroma"
      ],
      "metadata": {
        "id": "ioqRmqSlTfDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformers"
      ],
      "metadata": {
        "id": "msbfXssFTbxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompting"
      ],
      "metadata": {
        "id": "eR2LT9n_TxRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval-Augmented Genaration"
      ],
      "metadata": {
        "id": "kuqknrChT0z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning"
      ],
      "metadata": {
        "id": "qdHIVtO7UEz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PEFT, LoRA, QLoRA\n",
        "\n",
        "* Parameter-Efficient Fine-Tuning\n",
        "* Low-Rank Adaption of Large Language Models\n",
        "* Quantized Low-Rank Adaption"
      ],
      "metadata": {
        "id": "F3Rhj1PK7E40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examples"
      ],
      "metadata": {
        "id": "5npCxVKOzt6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Project\n",
        "\n",
        "* Production Level Data Science Process\n",
        "* https://www.springboard.com/blog/data-science/data-science-process/\n",
        "* Data Prep\n",
        "* Exploratory Data Analysis\n",
        "* Feature Engineering\n",
        "* Feature Selection (example Lasso, see Robert Tibshirani, https://en.wikipedia.org/wiki/Lasso_(statistics))\n",
        "* Model Building and Evaluation\n",
        "* Model Deployment"
      ],
      "metadata": {
        "id": "cQYs7bXdHK1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview\n",
        "\n",
        "* Python\n",
        "* Pipelines\n",
        "* Environments\n",
        "* Reproducibility\n",
        "* Streamlining\n",
        "* Achitecture"
      ],
      "metadata": {
        "id": "t46lUaT2J2Rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PrepPy\n",
        "\n",
        "PrepPy Examples Notebook"
      ],
      "metadata": {
        "id": "R1swm7XIzdVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Research Environment\n",
        "\n",
        "Notebooks\n",
        "* Data Acquisition\n",
        "* Data Prep\n",
        "* Exploratory Data Analysis\n",
        "* Feature Engineering\n",
        "* Feature Selection\n",
        "* Modeling and Evaluation"
      ],
      "metadata": {
        "id": "CqUpUPvbJ33J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Production Environment\n",
        "\n",
        "Key Features\n",
        "\n",
        "* Production code is intended for end users (not data scientists)\n",
        "* Testability and maintainability\n",
        "* Pep 8\n",
        "* Scalability and Performance (containerization)\n",
        "* Reproducibility (version control)\n",
        "\n",
        "Packaging\n",
        "\n",
        "* Module: a file which contains various Python functions and global variables\n",
        "* Package: a collection of modules\n",
        "\n",
        "API\n",
        "\n",
        "Model 1\n",
        "<pre>\n",
        "parent/\n",
        "|---regression model/\n",
        "|   ---config/\n",
        "|   ---datasets/\n",
        "|   ---processing/\n",
        "|   ---trained_models/\n",
        "|   ---config.yml\n",
        "|   ---pipeline.py\n",
        "|   ---predict.py\n",
        "|   ---train_pipeline.py\n",
        "|   ---VERSION\n",
        "|---requirements/\n",
        "|   ---requirements.txt\n",
        "|   ---test_requirements.txt\n",
        "|---tests/\n",
        "|---setup.py\n",
        "|---MANIFEST.in\n",
        "|---pyproject.toml\n",
        "|---tox.ini\n",
        "</pre>\n",
        "\n",
        "Model 2\n",
        "Github Actions\n",
        "\n",
        "Model 3\n",
        "Gitlab\n",
        "\n"
      ],
      "metadata": {
        "id": "JkDnRRtmJ7_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLOps vs DevOps\n",
        "\n",
        "* https://devops.com/mlops-vs-devops-whats-the-difference/\n"
      ],
      "metadata": {
        "id": "KrP6U8LST89v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuous Integration and Deployment\n",
        "\n",
        "* Continuous Integration\n",
        "* Continuous Deployment\n",
        "* Containers\n",
        "\n",
        "Readings:\n",
        "\n",
        "* https://medium.com/javarevisited/7-best-courses-to-learn-gitlab-for-developers-and-devops-engineers-10d4de4ae206\n",
        "* https://www.asapdevelopers.com/python-for-ci-cd/\n",
        "* https://realpython.com/python-continuous-integration/\n",
        "* https://www.reddit.com/r/gitlab/comments/1alawyd/gitlabcom_now_requires_credit_card_info_for/"
      ],
      "metadata": {
        "id": "3UmtWUCtKFUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing\n",
        "\n",
        "* Unit Testing\n",
        "* Pytest\n",
        "* Integration Testing\n",
        "* Differential Testing"
      ],
      "metadata": {
        "id": "jd0OcAQJKO9N"
      }
    }
  ]
}